看两本书：redis设计与实现、redis开发与运维




Redis
redis设计与实现
数据结构与对象
redis数据类型和数据结构：
- 首先在 Redis 内部会使用一个 RedisObject 对象来表示所有的 key 和 value
- Redis 提供了五种基本数据类型，String、Hash、List、Set、Zset(sorted set：有序集合)，以及其他不常用的数据类型：位图、HyperLogLog等。
- 由于 Redis 是基于标准 C 写的，只有最基础的数据类型，因此 Redis 为了满足对外使用的 5 种数据类型，开发了属于自己独有的一套基础数据结构，使用这些数据结构来实现5种数据类型。
- Redis底层的数据结构包括：简单动态数组SDS、链表、字典、跳跃链表、整数集合、压缩列表、对象。
- Redis 为了平衡空间和时间效率，针对 value 的具体类型在底层会采用不同的数据结构来实现
简单动态字符串SDS
struct sdshdr{
int len;
int free;
char buf[];
}
新版：
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
上面的 SDS 结构使用了范型 T，为什么不直接用 int 呢，这是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。
embstr和raw：Redis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。原因：
struct RedisObject {
    int4 type; // 4bits
    int4 encoding; // 4bits
    int24 lru; // 24bits
    int32 refcount; // 4bytes
    void *ptr; // 8bytes，64-bit system
} robj;

struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* used */
    uint8_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};

一个 RedisObject 对象头需要占据 16 字节的存储空间。在字符串比较小时，SDS 对象头的大小是capacity+3，至少是 3。意味着分配一个字符串的最小空间占用为 19 字节 (16+3)。embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。而内存分配器 jemalloc/tcmalloc 等分配内存大小的单位都是 2、4、8、16、32、64 等等，为了能容纳一个完整的 embstr 对象，jemalloc 最少会分配 32 字节的空间，如果字符串再稍微长一点，那就是 64 字节的空间。如果总体超出了 64 字节，Redis 认为它是一个大字符串，不再使用 emdstr 形式存储，而该用 raw 形式。当内存分配器分配了 64 空间时，那这个字符串的长度最大可以是多少呢？这个长度就是 44。那为什么是 44 呢？看上面这张图可以算出，留给 content 的长度最多只有 45(64-19) 字节了。字符串又是以\0结尾，所以 embstr 最大能容纳的字符串长度就是 44。（之前是39）

sds特点：1.常数复杂度获取字符串长度；2.杜绝缓冲区溢出；3.减少修改字符串带来的内存重分配次数；4.二进制安全
链表（废弃）
typedef struct listNode {
    struct listNode *prev;
    struct listNode *next;
    void *value;
}

typedef struct list {
    listNode *head;
    listNode *tail;
    unsigned long len;
    void dup();
    void free();
    void match();
}
特点：双端、无环、带头指针和尾指针、带长度计数器、多态。
快速列表（代替链表）
链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。

struct quicklistNode {
    quicklistNode* prev;
    quicklistNode* next;
    ziplist* zl; // 指向压缩列表
    int32 size; // ziplist 的字节总数
    int16 count; // ziplist 中的元素数量
    int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储
    ...
}struct quicklist {
    quicklistNode* head;
    quicklistNode* tail;
    long count; // 元素总数
    int nodes; // ziplist 节点的个数
    int compressDepth; // LZF 算法压缩深度
    ...
}
为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度。quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数list-max-ziplist-size决定。quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数list-compress-depth决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。如果深度为 2，就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。
字典
typedef struct dict{
    dictType *type;
    void *privdata;
    dictht ht[2];
    int trehashidx;//rehash进度，如果没有rehash则是1
}
typedef struct dictht{
    dictEntry table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
}
typedef struct dictEntry{
    void key;
    union{
        void *val;
        uint64_tu64;
    }
    struct dictEntry next;
}

hash\解决键冲突\
rehash：扩容和缩容通过rehash完成，如果是扩容，大小为之前的两倍；如果是缩容，大小为第一个大于等于used的2的n次方。扩展触发：没有BGSAVE且负载因子大于1或在执行BGSAVE且负载因子大于5；收缩触发：负载因子小于0.1.
渐进式rehash：1.为ht[1]分配空间；2.rehashidx设置为0；3.rehash期间对字典的修改操作通过ht[1]执行，查询先查0，没有再查1，且每次添加、删除、更新操作后顺带rehash并更新rehhashidx；4.定时任务里也会去rehash，最多花1毫秒去做rehash；5.完全迁移到ht[1]后，将rehash改成-1，ht[0]指向ht[1]，删除ht[1]指针。
go和redis的map区别：如果map在扩容，go在查找的时候会通过扩容地址直接判断key在新字典还是在老字典，redis直接在两个字典里查
https://blog.csdn.net/tptpppp/article/details/103510214
数据结构
- 相同：内部两个哈希表，用于扩容，但Go中叫做buckets和oldbuckets，Redis中是一个数组，大小为2
- 不同：层次不同。 参见上面的图，Redis第二层存储了子表的信息，第三层作为子表，存储的是实际数据的地址；Go实际只有三层。这导致两种实现后续功能的差异，如：是否支持缩容。
- 不同：size、used存储方式。Go在顶层结构中存储了B字段，表示有2^B个bucket，并存储了count字段表示已有数据个数；Redis在第二层(每个字表信息)中
- 不同：k-v排列方式。Go：8*key+8*val作为一个bucket，后面可以链式挂接更多overflow的bucket，Redis：key+val作为一个dictEntity，后面可以链式挂接更多dictEntity
哈希方式
- 相同：根据不同类型，调用不同的hash方法后，求余得到索引
- 不同：Redis：得到bucket索引后即得到bucket数据，二Go还需要再根据tophash->key的查找
冲突解决方式
- 相同：拉链法
- 不同：Redis的链表直接存在每个数据(dictEntity)后，Go由8个k-v组成一个bucket，然后再挂接overflow bucket
rehash
- 相同：装载因子的概念
- 相同：渐进式扩容 下文详细描述
- 不同：触发扩容的时机 Go在插入新key时检测装载因子和拉链长度，Redis在增删查改时都会检查是否需要rehash
- 不同：触发扩容的条件 Go：bucket内(可以存储8个k-v)的平均个数超过6.5或单个bucket的overflow超过bucket数会进行扩容；Redis：每个key平均存储了一个数据，则进行扩容；每个key平均存储了不到0.1个数据，则进行缩容
渐进式扩容
- 相同：第一次先分配空间，后面再渐进搬迁
- 不同：Go只在增删操作时搬迁，Redis在增删查改操作时都会进行渐进搬迁操作
缩容
- 不同：Go只保存了当前的bucket size，新bucket一定是旧bucket大小的两倍，不支持缩容。Redis的缩容：两个子表记录了自己的大小，缩容即扩容的逆过程。

跳跃表

跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。支持平均logn、最坏n的复杂度节点查找，还可以通过顺序性操作来批量处理节点。大部分情况，跳表的效率和平衡树差不多且跳表简单。
typedef struct zskiplist{
    structz skiplistNode header,tail;
    unsigned long length;
    int level;
}
typedef struct zskiplistNode{
    struct zskiplistLevel{
        struct zskiplistNode forward;
        unsigned int span;
    }level[];
    struct zskiplistNode backward;
    double score;
    robj obj;
}

整数集合
typedef struct intset{
    uint32_t encoding;
    uint32_t length;
    int8_t contents[];
}
contents数组不保存int8_t的值，他的真正类型取决于encoding属性的值
整数集合的升级：每当我们将一个新元素添加到整数集合里面，并且新元素的类型比整数集合现有所有元素的类型都长，整数集合需要先进行升级，然后再把新元素添加进去。升级步骤：1.根据新元素类型，扩展整数集合数组空间的大小并为新元素分配空间；2.将底层数组现有的所有元素都转成与新元素相同的类型并放在正确的位上且保证顺序；3.将新元素添加到底层数组里面。
升级的好处：提升整数集合的灵活性；尽可能节约内存。
降级：一旦对数组升级，则不会再降级。

压缩列表
压缩列表是为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构。

struct ziplist<T> {
    int32 zlbytes; // 整个压缩列表占用字节数
    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
    int16 zllength; // 元素个数
    T[] entries; // 元素内容列表，挨个挨个紧凑存储
    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
}
struct entry {
    int<var> prevlen; // 前一个 entry 的字节长度
    int<var> encoding; // 元素类型编码
    optional byte[] content; // 元素内容
}
zlbytes：记录整个压缩列表占用的内存字节数；
zltail：记录压缩列表尾节点距离压缩列表起始地址由多少节；
zllen：记录压缩列表包含的节点数量；
entryX：压缩列表的各个节点；
zleng：特殊值0xFF，用于标记压缩列表末端；

压缩列表节点构成：
1.previous_entry_length：记录压缩列表前一个节点的长度（压缩列表可以双向遍历的）；
2.encoding：节点content属性所保存数据的类型和长度；
3.content：节点保存的值，可以是数组或整数；
异常情况：连锁更新：多个连续、长度介于250字节到253字节之间的节点，由于添加一个大于254节点导致都需要更新。

紧凑列表
 listpack，它是对 ziplist 结构的改进，在存储空间上会更加节省，而且结构上也比 ziplist 要精简。
struct listpack<T> {
    int32 total_bytes; // 占用的总字节数
    int16 size; // 元素个数
    T[] entries; // 紧凑排列的元素列表
    int8 end; // 同 zlend 一样，恒为 0xFF
}

这个 listpack 跟 ziplist 的结构几乎一摸一样，只是少了一个zltail_offset字段。ziplist 通过这个字段来定位出最后一个元素的位置，用于逆序遍历。不过 listpack 可以通过其它方式来定位出最后一个元素的位置，所以zltail_offset字段就省掉了。
struct lpentry {
    int<var> encoding;
    optional byte[] content;
    int<var> length;
}
元素的结构和 ziplist 的元素结构也很类似，都是包含三个字段。不同的是长度字段放在了元素的尾部，而且存储的不是上一个元素的长度，是当前元素的长度。正是因为长度放在了尾部，所以可以省去了zltail_offset字段来标记最后一个元素的位置，这个位置可以通过total_bytes字段和最后一个元素的长度字段计算出来。最大的好处是彻底消灭了 ziplist 存在的级联更新行为。

基数树
Rax 是 Redis 内部比较特殊的一个数据结构，它是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操作。Redis 五大基础数据结构里面，能作为字典使用的有 hash 和 zset。hash 不具备排序功能，zset 则是按照 score 进行排序的。rax 跟 zset 的不同在于它是按照 key 进行排序的。

应用：你可以将一本英语字典看成一棵 radix tree，它所有的单词都是按照字典序进行排列，每个词汇都会附带一个解释，这个解释就是 key 对应的 value。有了这棵树，你就可以快速地检索单词，还可以查询以某个前缀开头的单词有哪些。


对象
每当我们在redis数据库新建一个键值对，我们至少创建两个对象。
typedef struct redisObject{
    unsigned type;
    unsigned encoding;
    void ptr;
    lru;//最后一次访问时间
}
新版：
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or
                            * LFU data (least significant 8 bits frequency
                            * and most significant 16 bits access time). */
    int refcount;
    void *ptr;
} robj;
type：字符串、列表、hash、集合、有序集合
每种类型的对象都至少实现了两种不同的编码

内存回收：引用计数法实现的内存回收机制。
对象共享：redis会共享值为0到9999的字符串对象。

单机数据库实现
数据库
struct redisServer{
redisDb *db;
int dbnum;
...
}

typedef struct redisDb{
    dict *dict;
    dict *expires;
    ...
}

过期键判定：1.检查给定键是否存在于过期字典，如果存在则取得键的过期时间；2.检查当前unix时间戳是否大于过期时间，如果是则键已经过期。

过期键删除策略：1.定时删除：在设置键的过期时间时创建一个定时器，让定时器在键过期时间来临时立刻执行键的删除操作。对内存最友好，对cpu最不友好；且当前时间事件是链表，不够高效；2.惰性删除：放任过期键不管，每次从键空间获取键时都检查键是否过期，如果过期则删除，内存不友好，cpu友好3.定期删除：每隔一段时间程序对数据库进行一次检查，删除过期的键，至于删除多少或检查多少数据库由算法决定。
redis的过期键删除策略：惰性删除加定期删除。惰性删除时遇到过期的键也不是直接删除，如果对象很大则放到一个垃圾链表里由异步线程去删除。定期删除：redis定时任务执行，如果没有带过期时间的键则跳过，随机取一个带有过期时间的键并检查是否过期，如果过期则删除，达到时间上限则停止。

RDB持久化
AOF持久化
事件
客户端
服务端
多机数据库实现
独立功能实现






















redis开发与运维
单机
如何使用
redis简介：
      - 是什么：REmote DIctionary Server(远程字典服务器)。
      - 优点：高性能、高可用、数据结构丰富、功能丰富、简单稳定。
      - 使用场景：缓存、排行榜、计数器、消息队列。
      - 可执行文件：redis-server\redis-cli\redis-benchmark\redis-check-aof\redis-check-dump\redis-sentinel
      - 配置文件：/opt/reids/redis.conf
      - 数据结构：字符串、hash、列表、集合、有序集合


      - 单线程为什么这么快：纯内存访问、非阻塞IO（epoll作为IO多路复用技术的实现）、单线程避免了线程切换和竞态产生的消耗。（redis把处理网络收发和执行命令这些操作都放在了主工作线程，但是除此之外还有许多bio后台线程也在兢兢业业的工作着，比如用来处理关闭文件和刷盘这些比较重的IO操作，这次bio家族又加入了新的小伙伴——lazyfree线程。多进程：AOF和RDB；多线程：lazyfree：bioProcessBackgroundJobs）


好处：可以改进内部编码而对外部数据结构和命令无影响；多种编码实现可以在不同的场景下发挥各自的优点。
常用功能
      - 字符串：
        - 内部编码：int（8个字节的长整型）、embstr（小于等于39字节的字符串）、raw（大于39字节的字符串）
        - 使用场景：缓存、计数、共享session
      - hash：
        - 内部编码：ziplist（hash元素个数小于hash-max-ziplist-entries默认512且所有的值都小于hash-max-ziplist-value默认64字节）、hashtable
        - 使用场景：缓存
      - 列表：
        - 内部编码：ziplist（列表个数小于list-max-ziplist-entries512且每个元素的值小于list-max-ziplist-value）、linkedlist
        - 使用场景：消息队列、文章列表
      - 集合：
        - 内部编码：intset（整数集合，元素都是整数且个数小于set-max-intset-entries512）hashtable
        - 标签
      - 有序集合：
        - 内部编码：ziplist（个数小于zset-max-liplist-entries128且每个元素小于zset-max-ziplist-value64字节）、skiplist
        - 使用场景：用户点赞
      - 遍历
        - Keys
        - Scan cursor
      - 限流
        - 简单限流：使用zset，value是时间戳，每次使用前将过期的value删除。
        - 漏斗限流：cl.throttle laoqian:reply 15 30 60 1
      - 分布式锁
分布式锁proposal
不常用功能
      - 慢查询分析
        - slowlog-log-slower-than和slowlog-max-len两个参数
        - 建议：线上调大慢查询列表，默认判断超过10毫秒为慢查询，可以调低一点1毫秒。
      - Pipeline
        - 节约网络开销
        - 和原生批量命令对比：1.原生批量命令是原子的；2.原生批量命令是一个命令对应多个key，pipeline是多个命令；3.原生批量命令由redis服务端支持，pipeline需要客户端和服务端共同实现。
      - 事务和lua
        - redis的简单事务：multi和exec之间的操作。如果有命令错误则整个事务无法执行；如果是运行时错误则整个事务执行一半；redis事务不支持回滚，没有原子性，只有隔离性。
        - 事务特性：
          1. 单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
          2. 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题
          3. 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，如果在一个事务中的命令出现错误，那么所有的命令都不会执行，如果在一个事务中出现运行错误，那么正确的命令会被执行，没有回滚。
        - lua脚本：eval和evalsha，脚本的加载和执行
      - Bitmaps（字符串类型）
        - Setbit key offset value
        - 优点：节约空间（存储每天访问的用户ID）
      - hyperloglog（字符串类型，基数算法）
        - 用处：利用极小的内存完成独立总数的统计0.81%的失误率。
        - Pfadd pfcount。
      - 布隆过滤器
        - bf.add,bf.exists
        - 用处：查询是否存在
      - 发布订阅：
        - Publish channel message\subscribe channel
      - GEO
客户端
      - 通信协议
        1. 单行字符串 以 + 符号开头。
        2. 多行字符串 以 $ 符号开头，后跟字符串长度。
        3. 整数值 以 : 符号开头，后跟整数的字符串形式。
        4. 错误消息 以 - 符号开头。
        5. 数组 以 * 号开头，后跟数组的长度。
      - 客户端管理
        - Client list
        - 输入缓存区：qbuf，作用是将客户端发送的命令临时保存，同时redis会从输入缓存区拉取命令执行
        - 输出缓冲区：obl：redis为每个客户端分配了输出缓冲区，作用是保存命令执行的结果返回给客户端
    - 和memcached的区别：
      1. 存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。
      2. 数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，而redis支持五种数据类型。
      3. 使用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
      4. value的大小：redis可以达到1GB，而memcache只有1MB。
如何更好的用
持久化
      - RDB：是把当前进程数据生成快照保存在硬盘的过程，分为手动触发（save和bgsave）和自动触发（save m n）


        - 流程：
          - 执行bgsave命令，如果当前存在正在执行的子进程如RDB、AOF，直接返回
          - 父进程执行fork创建子进程，fork操作过程父进程会阻塞，fork完成后父进程响应其他命令
          - 子进程创建RDB文件，根据父进程内存生成的临时快照文件，完成后对原有文件进行原子替换
          - 进程发送信号通知父进程完成
        - 优缺点
          - 优点：是一个紧凑的二进制文件，适用于备份
          - 缺点：没办法做到实时的持久化
      - AOF：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的，主要为了解决数据持久化的实时性。开启AOF功能需要配置appendonly yes。


        - 过程
          - 所有写入命令追加到aof_buf中。
          - aof缓冲区根据对应策略向硬盘做同步（always：命令写入aof_buf后调用fsync同步AOF文件、everysec默认：命令写入aof_buf后调用write操作，sfync由专门的线程每秒调用一次、no：命令写入aof_buf后调用write操作，不对AOF做sfync同步，由操作系统负责，通常不超过30秒）。
          - 随着AOF文件越来越大，需要定期对AOF文件进行重写达到压缩的目的。可以通过手动触发（bgrewriteaof）和自动触发（auto-aof-rewrite-min-size）


            - 执行AOF重写请求
            - 父进程执行fork创建子进程，创建完成后继续响应其他命令；所有修改依然写入AOF缓存区并根据appendfsync策略同步到硬盘，保证原有AOF机制正确性；由于fork操作运用写时复制技术，子进程只能共享fork操作时的内存数据，由于父进程依然响应命令，redis使用AOF重写缓存区（是一个block链表，每个block10MB）保存这部分数据。
            - 子进程根据内存快照按照命令合并规则写入到新的AOF文件
            - 新AOF文件写完后，子进程发送信号给父进程
            - 父进程把AOF重写缓冲区的数据写入新的AOF文件
            - 使用新的AOF文件替换老文件
          - 当Redis重启时，可以加载AOF文件进行数据恢复


      - 问题定位和优化
        - fork操作：fork创建的子进程不需要拷贝父进程的物理内存空间，但是会复制父进程的空间内存页表，对于10G的redis进程，需要复制大概20MB的内存页表。
        - 子进程开销
          - cpu：开销很大，会和父进程产生单核资源竞争，如果部署多个redis实例不要同时创建子进程。
          - 内存：开销不大，也要注意
          - 硬盘，开销很大
        - AOF追加阻塞：AOF持久化常见策略是everysec，redis使用另一个线程每秒执行fsync同步硬盘，如果系统硬盘资源繁忙，会造成redis祝线程阻塞。


          - 祝线程负责写AOF缓存区
          - AOF线程负责每秒执行一次同步操作并记录最近一次同步的时间
          - 主线程会对比上次AOF同步时间，如果距上次同步完成在2秒内，主线程直接返回；如果大于2秒，主线程会阻塞，知道同步操作完成。所以everysec配置最多丢2秒数据。
      - 多实例部署：


阻塞
      - 内在原因（redis自身原因导致的）：
        - API或数据结构不合理：如hgetall、keys；大对象拆分。
        - CPU饱和：使用统计命令redis-cli-h{ip}-p{port} --stat判断redis状态；过度使用ziplist等。
        - 持久化相关阻塞：fork阻塞（避免使用过大内存）、AOF刷盘阻塞（硬盘压力大）、hugepage写操作阻塞（写时复制技术，内存页单位太大4K-》2MB）
      - 外在原因
        - cpu竞争：进程竞争、绑定cpu（为了降低cpu频繁上下文切换，但是在RDB、AOF重写时会和父进程共享一个cpu造成竞争）
        - 内存交换：redis保证高性能的重要前提是所有的数据都在内存中，如果操作系统把redis使用的部分内存换出硬盘，会导致发生交换后的redis性能急剧下降。发现方法：查询redis进程号，根据进程号查询内存交换信息。预防内存交换的方法：保证机器充足的内存、设置redis实例的最大可用内存、降低系统swap的优先级
        - 网络问题
          - 连接拒绝
            - 网络闪断或带宽耗尽
            - redis连接拒绝。redis通过maxclients参数控制客户端最大连接数，默认10000。客户端访问redis尽量曹勇NIO长连接或连接池的方式。
            - 连接溢出：操作系统或redis客户端在连接时的问题。可能原因：进程限制（进程可打开最大文件数控制，默认1024，可以设置成65535）、backlog队列溢出（系统对于特定端口的TCP连接使用backlog队列保存，默认长度为511，可以增大）。
          - 网络延迟
理解线程模型：


      - Redis 基于 Reactor 模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以 Redis 才叫单线程模型。
      - 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
      - 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
      - 虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。
理解内存
      - 内存消耗分析
        - redis进程内消耗：
          - 自身内存：很少
          - 对象内存：最大
          - 缓冲内存：客户端缓冲（每个客户端最大1G，在大流量场景中容易失控）、复制积压缓冲（默认1MB，可以适当增大）、AOF缓冲（用户无法控制，取决于AOF重写时间和写入命令量，通常很小）
          - 内存碎片：redis默认内存分配器是jemalloc，可选还有glibc、tcmalloc；正常的碎片率在1.03左右；出现高碎片率解决方法：1.数据对齐；2.安全重启
        - redis子进程内存消耗：AOF、RDB重写时创建子进程内存消耗
      - 管理内存的原理和方法
        - 控制内存上限：redis默认无限使用服务器内存，maxmemory参数限制最大内存，目的：当用于缓存场景时使用LRU等策略释放空间；防止使用内存超过服务器物理内存（需要预留部分服务器物理内存给碎片）。
        - 回收策略：
          - 删除到达过期时间的键对象
            - 惰性删除：当客户端读取带有超时时间的键，如果已经过期，则删除并返回空。
            - 定时任务删除：redis内部维护一个定时任务，默认每秒运行10次，定时任务中删除过期键采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键。
              - 定时任务在每个数据库空间随机检查20个键，当发现过期删除对应的键。
              - 如果有超过25%的键过期，循环执行回收逻辑直到不足25%或运行超时，慢模式下超时时间为25毫秒。
              - 如果之前回收键逻辑超时，则redis触发内部事件之前再次以快模式运行回收过期键任务，快模式下超时时间为1毫秒且2秒内只能运行1次。
              - 快慢模式内部删除逻辑相同，只是执行时间不同。
          - 手动删除键对象
          - 内存使用达到maxmemory上限时触发内存溢出控制策略：
            - 默认：不删除任何数据，拒绝所有写操作并返回错误信息。
            - 超时键LRU：根据LRU算法删除设置了超时属性的键，直到腾出足够的内存，如果没有可删除的键，回退到默认策略。
            - 所有键LRU：不管数据有没有设置超时。
            - 随机：随机删除所有键直到腾出空间
            - 超时随机：随机删除过期键
          - 命令触发删除以及延迟删除时，先从map里将要删除的键值对dictEntry的引用去除，这时需要分别删除dictEntry里的key和value，如果判断value的引用计数为1并且value满足延迟删除条件（value的元素个数超过64个），则将value放到延迟删除队列里并将dictEntry里的value引用改为null。然后分别将dictEntry、dictEntry的key和value删除。value由异步线程去删除。
      - 内存优化技巧
        - 减少redisobject内存分配次数：字符串小于44字节
        - 缩小键值的长度
        - 共享对象池（0～9999的整数对象池），在满足需求的前提下尽量使用整数对象节约内存。为什么只有整数有对象池：1.整数对象复用概率最大；2.整数判断相等复杂度最低。
        - 字符串优化：
        - 编码优化：
        - 控制键的数量，分散到hash里。
集群
复制：为了实现高可用
使用
      - 配置：参与复制的redis划分为主节点和从节点，默认情况下，redis都是主节点。配置方式有三种：
        - 配置文件中加入slaveof{masterHost}{masterPort}随redis启动生效；
        - redis-server启动命令后加入--slaveof{}{};
        - 直接使用命令：slaveof{}{};
      - 断开复制：sloveof no one.1.断开与主节点复制关系；2.从节点晋升为主节点
      - 切主操作：sloveof。切主操作会删除从节点当前所有数据
      - 默认情况从节点用slove-read-only=yes配置为只读模式。
      - 传输延迟：redis提供repl-disable-tcp-nodelay参数用来控制是否关闭TCP_NODELAY。如果关闭，主节点产生的命令数据无论大小都会即时的发送给从节点；开启时，主节点会合并较小的TCP数据包从而节约带宽。默认发送间隔一般40毫秒，节省了带宽但增大了延迟。
      - 拓扑结构：
        - 一主一从
        - 一主多从
        - 树状主从
原理：
      - 流程：
        - 保存主节点的信息
        - 主从建立socket连接
        - 发送ping命令
        - 权限验证
        - 同步数据集
        - 命令持续复制
      - 数据同步
        - 全量复制：初次复制场景
        - 部分复制：用于处理主从复制中因网络等原因造成的数据丢失，当从节点重新连接上时，如果条件允许可以只补发丢失的数据。
          - 参与复制的主从节点都会维护自身的复制偏移量。
          - 主节点会保留一个复制挤压缓存区，默认为1MB，当主节点又连接从节点时创建，这时主节点在相应写命令时，不但会把命令发送给从节点，也会写入复制积压缓存区。
          - 每个redis节点启动后都会动态分配一个运行id，如果运行id变化，从节点基于偏移量复制数据不安全。
          - 从节点可以使用psync命令完成部分复制和全量复制功能：psync {runld}{offset}
          - 复制流程(全量复制)：
            - 1.发送psync命令进行数据同步，由于第一次复制，从节点没有复制偏移量和主节点运行ID，所以发送psync-1
            - 主节点解析为全量复制，恢复FULLRESYNC响应
            - 从节点接收主节点的响应数据保存运行ID和偏移量offset
            - 主节点执行bgsave保存RDB文件到本地
            - 主节点发送RDB文件给从节点，从节点把接收的RDB文件保存在本地。对于数据量较大的主节点，传输文件很耗时，如果总时间超过reol-timeout会失败。
            - 从节点开始接收RDB快照到接收完成期间，主节点依然在响应读写命令。这个时候主节点会把命令数据保存在复制客户端缓存内。如果主节点复制客户端缓冲区溢出会导致同步失败。
            - 从节点接收主节点传过来的数据后会删除自身的旧数据
            - 数据清空后开始加载RDB文件。
            - 从节点成功加载完RDB后，如果开启了AOF持久化功能，会开始做bgrewriteaof操作


        - 心跳：主从节点在建立复制后，会维护长连接并彼此发送心跳命令；主节点默认每隔10秒对从节点发送ping命令判断从节点的存活性；从节点每隔一秒发送心跳给主节点上报自身的复制偏移量。
运维中的问题
        - 读写分离：对于读占比比较高的场景，可以通过把一部分读流量分摊到从节点，同时永远只对主节点执行写操作。如果延迟设置报警，修改读命令路由到其他从节点或主节点。
        - 规避全量复制：第一次建立时全量复制无法避免；主节点故障重启尽量不更改节点运行ID；增大复制积压缓冲区。
        - 规避复制风暴：指的是大量从节点对同一个主节点或同一个主机上的多个主节点短时间内发起全量复制的过程。减少从节点挂载数量；主节点分散到多个机器上
哨兵：redis sentinel是redis的高可用实现方案。
基本概念：
      - 主从复制的问题：主节点故障需要手动将一个从节点晋升为主节点，同时需要修改应用方主节点地址，还要命令其他从节点去复制新的主节点，整个过程都需要人工干预且主节点的写能力受到单机的限制；为了实现高可用，需要将上述流程自动化。redis Sentinel可以自动完成故障发现和故障转移并通知应用方，从而实现真正的高可用。
      - Redis sentinel：是一个分布式架构，其中包含若干个sentinel节点和redis数据节点，每个sentinel节点都会对数据节点和其余sentinel节点做监控，当他发现节点不可达时，会对节点做下线标示，如果被标示的是主节点，它还会和其他sentinel节点进行协商，当大多数sentinel节点都认为主节点不可达时，他们会选举一个sentinel节点来完成自动故障转移工作，同时会将这个变化通知给redis使用方。整个过程完全自动。
      - 故障转移的四个步骤：
        - 主节点出现故障，和两个从节点失去连接。
        - 每个sentinel节点通过定时监控发现主节点出现了故障
        - 多个sentinel节点对主节点的故障达成一致，选举出某个sentinel节点作为领导者负责故障转移。
        - sentinel完成故障转移。
        - sentinel节点将故障转移的结果通知给应用方。
安装和部署


      - 部署：
        - 启动主节点
        - 启动从节点
        - 确认主从关系
        - 部署sentinel节点：配置sentinel monitor master ip port；启动：redis-sentinel redis-sentinel.conf（sentinel节点本质上是一个特殊的redis节点）
      - 配置说明
        - Sentinel monitor master-name ip port quorum（主节点故障判定票数，建议一半加一，也和领导者票数有关；可以监控多个主节点）。sentinel节点会定期监控主节点，并且也会监控其他所有节点，其他从节点和其余sentinel节点的信息会从主节点获取。
        - Sentinel down-after-milliseconds。每个sentinel节点都会通过定期发送ping命令来判断redis数据节点和其他sentinel节点是否可达，如果超过down-after-milliseconds时间没收到有效回复则判断不可达。越大则故障转移时间越长，越小则误判概率越大。
      - 部署技巧
        - snetinel节点不要部署在一台物理机器上；
        - 部署至少三个且奇数个sentinel节点；
        - 多个主节点用一套sentinel还是多套：一套：降低了维护成本但可用性降低。一般建议使用多套。
      - API：
        - Sentinel masters：展示所有被监控的主节点状态和统计信息。
        - Sentinel slaves<master name>展示master name的从节点状态和统计信息
      - 客户端连接（各个语言的客户端需要显式的对redis sentinel支持，客户端连接必须要sentinel节点集合和mastername两个参数）
        - Redis sentine客户端实现原理：
          - 遍历sentinel节点集合获取一个可用的sentinel节点
          - 通过sentinel的API获取对应的主节点相关信息
          - 验证当前获取的主节点是正确的
          - 保持和sentinel节点集合的联系，随时获取关于主节点的相关信息
Redis sentinel实现原理：
        - sentinel的三个定时任务
          - 每隔10秒，每个sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构。目的：获取从节点信息、感知新的从节点、实时更新节点拓扑信息。
          - 每隔2秒，每个sentinel节点会向redis数据节点的__sentinel__:hello频道上发送该sentinel节点对于主节点的判断以及当前sentinel节点的信息；每个sentinel节点也会订阅这个频道获取其他sentinel节点以及它们对主节点的判断。目的：发现新的sentinel节点、sentinel节点之间交换主节点状态。
          - 每隔1秒，每个sentinel节点会向其他所有redis数据节点和sentinel节点发送ping命令做一次心跳检测，来确认节点是否可达。目的：实现了对每个节点的监控。
        - 主观下线和客观下线
          - 主观下线：当一个sentinel发现某个节点超过down-after-millisenconds没有进行有效回复，会对它做失败判断，这个是主观下线。
          - 客观下线：当sentinel主观下线的节点是主节点时，该sentinel节点会通过sentinel is-master-down-by-addr命令向其他sentinel节点询问对主节点的判断，当超过quorum个数sentinel节点认为主节点有问题，则该sentinel节点会作出客观下线的决定。从节点和sentinel节点在主观下线后没有后续的故障转移操作。
        - sentinel领导者选举
          - 每个在线的sentinel节点都有资格称为领导者，当它确定主节点主观下线时，会向其他sentinel节点发送sentinel is-master-down-by-addr命令要求将自己设置成领导者。
          - 收到命令的sentinel节点，如果没有同意过其他sentinel节点的这个命令，将同意该请求，否则拒绝。
          - 如果该sentinel节点发现自己的票数以及大于等于max(quorum,num(sentinels)/2+1)，那么它会成为领导者。
          - 如果此过程没有选举出领导者，将进入下次选举。
        - 故障转移
          - 在从节点列表中选一个节点作为新的主节点
            - 过滤不健康（主观下线、断线）的节点
            - 选择slave-priority最高的从节点列表，如果存在则返回
            - 选择复制偏移量最大的从节点，如果存在则返回
            - 选择runid最小的从节点
          - sentinel领导者会对选出来的从节点执行slaveof no one操作让其成为主节点
          - sentinel领导者向剩余从节点发送命令，让它们成为新的主节点的从节点
          - sentnel节点集合将原来的主节点更新为从节点并保持对其关注，当其恢复后命令它去复制新的主节点。
集群：遇到单机内存、并发、流量瓶颈，可以采用Cluster架构方案达到负载均衡目的
数据分布
      - hash分区
        - 节点取余：优点简单；缺点扩容麻烦，需要翻倍扩容，避免数据映射全部被打乱导致全量迁移。
        - 一致性hash分区：为每个系统中的每个节点分配一个token，范围在0～2的32次方，这些token构成一个hash环。数据读写执行节点查找操作时先根据key计算hash值，然后顺时针找到第一个大于等于该hash值的token节点。好处是加入和删除节点只影响hash环中相邻的节点；缺点有：加减节点同样会造成hash环中部分数据无法命中，需要手动处理或者忽略，因此一致性hash通常用于缓存；如果节点很少，节点变化会影响很多数据，所以不适合节点数量很少的情况。
        - 虚拟槽分区：巧妙使用了hash空间，使用分散度良好的hash函数把所有数据映射到一个固定范围的整数集合中，整数被定义为槽，这个范围一般远远大于节点数（redis cluster槽范围0～16383），槽是集群内数据管理和迁移的基本单位，每个节点负责一定数量的槽。好处：解耦数据和节点的关系，简化节点扩容和所容难度。
        - 集群限制：
          - key批量操作支持有限如mget、mset
          - key事务操作支持有限，只支持多个key在一个节点的事务操作；
          - 集群模式只能使用一个数据库空间
          - 复制结构只支持一层
集群搭建
      - 准备节点：（节点数量至少6个）每个节点配置cluster-enabled yes


      - 节点握手：由客户端发起命令：cluster meet {ip} {port}
        - 节点A本地创建节点B的信息对象并发送meet消息
        - 节点B接收meet消息后，保存节点A的信息并恢复
        - 之后节点A、B彼此通过ping、pong消息进行正常的节点通信
        - 只需要在集群内任意节点上执行cluster meet命令加入新节点，握手状态会通过消息在集群内传播，其他节点会自动发现新节点并发起握手流程。
      - 分配槽:
        - 节点握手完成后集群还不能正常工作，处于下线状态（被分配的槽是0）
        - redis集群把所有的数据映射到16384个槽中，每个key会映射到一个固定的槽上，使用cluster addslots [...]为节点分配槽。所有的槽都分配好之后集群变成在线状态。首次启动的节点和被分配槽的节点为主节点。从节点负责复制主节点的槽信息和相关数据。
节点通信
      - 分布式存储中需要维护节点元数据信息机制，常见的元数据维护方式分为集中式和P2P式。redis采用P2P的Gossip（流言）协议。工作原理是节点彼此不断通信交换信息，一段时间后所有的节点都会直到集群的完整信息。
      - 通信过程：
        - 集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信
        - 每个节点在固定周期内通过特定规则选择几个节点发送ping消息
        - 接收到ping消息的节点用pong消息响应
      - Gossip消息分类
        - Meet：用于通知新节点加入，消息发送者通知接收者加入到当前集群
        - Ping：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息用来检测节点是否在线和交换彼此状态信息。
        - Pong：作为响应方恢复ping和meet。
        - fail：当节点判断集群内另一个节点下线时，会向集群广播一个fail消息通知其他节点。
      - 节点选择：redis集群内节点通信采用固定频率（每秒10次），所以通信节点选择很重要，需要兼顾信息交换实时性和成本开销。
        - cluster_node_timeout参数对消息发送的节点数量影响很大，如果带宽紧张可以适当加大，太大会影响故障转移速度。消息体携带数据量和集群节点数量相关，更大的集群每次消息通信的成本很大。


集群伸缩：集群伸缩即槽和数据在节点之间的移动
      - 扩容：
        - 准备新节点
        - 加入集群
        - 迁移槽和数据（或作为其他主节点的备份）
          - 槽迁移计划
          - 迁移数据
          - 通知集群内主节点，通知槽分配给目标节点，为了保证槽节点映射及时传播，需要遍历发送给所有的主节点更新被迁移的槽指向新节点。
      - 收缩集群：
        - 如果下线节点有负责的槽，需要先把槽迁移到其他节点
        - 通知集群内其他节点忘记下线节点，当所有节点忘记该节点后可以正常关闭


请求路由
      - 分区实现方案：
        1. 客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。
        2. 代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy
        3. 查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。
      - 请求重定向：在集群模式下，redis接收任何键相关的命令先计算键对应的槽，在根据槽找到对应的节点，如果是自身则处理命令，否则回复重定向错误通知客户端请求正确的节点。好处是简单，缺点是增加了IO开销，所以通常使用smart客户端。


      - smart客户端
        - 原理：smart客户端内部维护slot->node的映射关系，本地可以实现键到节点的查找。
        - Jedis原理：
          - 初始化：
            - Jedis cluster初始化时会选择一个运行节点，初始化槽和节点映射关系
            - Jedis cluster解析cluster slots结果缓存在本地并为每个节点创建唯一的JedisPool连接池
          - 键命令流程：
            - 计算slot并根据slots缓存获取目标节点连接，发送命令
            - 如果出现连接错误，使用随机活跃节点连接重新执行命令
            - 捕获重定向错误，使用cluster slots命令更新slots缓存
            - 重复1～3步直到命令成功，或者重试次数用完抛出异常


      - ASK重定向
        - slot对应的数据在迁移过程中，客户端需要只能识别保证键命令可以正常执行，在执行键命令时如果发现键不存在，则可能存在目标节点，这时源节点会回复ASK重定向异常；这时客户端从异常中提取目标节点信息，在目标节点执行键命令。


        - ASK和MOVED重定向区别：ASK重定向说明集群正在进行slot数据迁移，客户端不知道什么时候迁移完成，所以只是临时性的重定向，客户端不会更新slots缓存；MOVED重定向说明键对应的槽已经迁移到新的节点，因此需要更新slots缓存。
故障转移
      - 故障发现：主观下线和客观下线
        - 主观下线：cluster-note-timeout时间内某个节点无法与另一个节点完成ping消息通信则标记为主观下线状态，当某个节点判断另一个节点主观下线后，相应的节点状态会随消息在集群内传播，当接受节点发现消息体有主观下线的节点状态时，会在本地找到故障节点的clusternode结构保存到下线报告链表中。当半数以上持有槽的主节点都标记某个节点是主观下线后，触发客观下线流程。
        - 客观下线：


        - 故障恢复：如果下线节点是持有槽的主节点则需要在它的从节点中选一个替换它。
          - 资格检查（与主节点断线时间）
          - 准备选举时间
          - 发起选举
          - 选举投票
          - 替换主节点
        - 故障转移时间：主观下线识别时间+主观下线消息传播时间+从节点转移时间
集群运维
      - 为了保证集群完整性，默认情况下当集群有任意一个槽没有分配到节点时整个集群不可用。这样会造成持有槽的主节点下线时，从故障发现到自动完成转移期间整个集群都不可用，所以建议把cluster-require-full-coverage配置为no
      - 由于Gossip消息通信的带宽消耗，建议集群最大规模在1000以内。
      - 集群倾斜：
        - 数据倾斜：节点和槽分配不均、不同槽对应的键差异过大（大量使用hash_tag）
        - 请求倾斜：热点key。解决：不使用热键作为hash_tag、本地缓存
      - 读写分离：集群模式下从节点不接受任何读写请求，发送过来的键命令会重定向到负责槽的主节点上。如果需要使用从节点分担主节点读压力，使用readonly命令打开客户端连接只读状态。打开后从节点接收读命令处理流程：如果对应的槽属于自己正在复制的主节点则直接执行读命令。一般直接扩展主节点数量提高集群性能，不建议在集群模式下做读写分离。
    - redis分区缺点：
      1. 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。
      2. 同时操作多个key,则不能使用Redis事务.
      3. 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集
      4. 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。
      5. 分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。

日常开发要点
缓存设计
    - 优点和缺点（用户体验和成本）
      - 优点：响应更快，用户体验更好、降低后端负载
      - 缺点：数据不一致性、代码维护成本、运维成本
    - 更新策略（从一致性和维护成本两个方面看）
      - LRU、LFU、FIFO算法剔除
        - 一致性：最差
        - 维护成本：低
      - 超时剔除
        - 一致性：一段时间内不一致
        - 维护成本：低
      - 主动更新（更新数据库后删除缓存）
        - 一致性：最高
        - 维护成本：较高
      - 总结：低一致性的场景使用内存限制加淘汰策略；高一致性场景使用超时剔除加主动更新
    - 穿透优化：缓存穿透指的是查一个缓存层和存储层根本不存在的数据。将导致每次查询不存在的数据都会去查存储层，失去了缓存保护存储的意义，使后端存储负载加大。造成原因：自身数据出现问题或被恶意攻击。
      - 缓存空对象（需要更多的内存空间，如果是攻击的化更严重；可能造成数据不一致）
      - 布隆过滤器拦截：在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来做第一层拦截（缓存占用空间少，代码维护复杂）
    - 雪崩优化：由于缓存层承载大量请求，有效的保护了存储层，如果缓存层由于某些原因无法提供服务将打挂存储层
      - 保证缓存服务高可用
      - 依赖隔离组件为后端限流和降级
    - 无底洞优化：无底洞指的是增加缓存节点不能改善性能问题。
      - 原因：键值数据库通常采用hash函数将key映射到不同节点上，如果增加大量节点做扩容，导致键分布到更多的节点上，批量操作（mget）通常需要从不同的节点获取，涉及更多的网络IO。
      - mget的优化：
        - 串行命令；优点：编程简单。缺点：大量key请求延时严重
        - 串行IO：优点：编程简单。缺点：大量node延迟严重
        - 并行IO：优点：利用并行特性，延迟取决于最慢的节点。缺点：维护复杂
        - hash_tag：将多个key强制分配到一个节点上。缺点：容易出现数据倾斜
    - 热key优化：如果一个key是热key，并发量很大，并且重建缓存不能在短时间完成，那么在缓存实效的瞬间会有大量线程来重建缓存，可能直接打挂存储。解决问题的思路有：减少重建缓存的次数；数据尽可能一致
      - 互斥锁：只让一个线程重建缓存；
      - 永远不过期：为每个value设置一个逻辑过期时间，当发现超过后用单独的线程去构建缓存。
    - 如何保证数据库和缓存数据一致性：
      - 读操作的固定的套路：
        - 如果我们的数据在缓存里边有，那么就直接取缓存的。
        - 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后将数据库查出来的数据写到缓存中。
        - 最后将数据返回给请求
      - 写操作流程分析：
        - 操作数据库时一般删除缓存而不是更新缓存：
          1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就更加容易导致数据库与缓存数据不一致问题。(删除缓存直接和简单很多)
          2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现懒加载)
        - 先删除缓存，再更新数据库
          - 在高并发下表现不如意，在原子性被破坏时表现优异
        - 先更新数据库，再删除缓存(Cache Aside Pattern设计模式)
          - 在高并发下表现优异，在原子性被破坏时表现不如意
开发陷阱
    - linux配置优化
    - 误操作优化（flushall和flushdb）
      - AOF机制恢复：redis执行了flush操作后，会在AOF文件中追加一条记录，如果发生AOF重写就没办法了，所以当误操作后要调大AOF的重写参数auto-aof-rewrite-percentage和auto-aof-rewrite-min-size并拒绝手动bgrewriteaof；将AOF文件里的flush相关操作去掉再使用redis-check-aof检查，确保无问题后使用AOF文件恢复。
      - RDB：如果没有开启RDB自动策略，可以作为恢复源，只是没有AOF实时性高；如果开启了RDB自动策略，由于flush涉及的键很多，所以RDB文件会被清除。
      - 从节点将会同步主节点的flush命令，所以从节点的RDB和AOF和主节点无区别。
    - 安全：
      - redis设计目标是一个在内网使用的一个轻量级高性能键值服务，所以对于安全方面没有太多工作（防止找到redis防止获取redis权限和防止获取redis权限后做坏事）
      - 不使用默认端口
      - 防火墙
      - Bind
      - 密码机制
      - 伪装危险命令
      - 定期备份数据
      - 使用非root用户启动
    - 处理bigkey（字符串类型：单个value值很大；非字符串类型：元素多）
      - 危害：内存空间不均匀；超时阻塞；网络拥塞。
      - 发现：redis-cli-bigkeys、debeg object key、scan加debug object主动检测。
      - 如何删除：del会阻塞redis，可以使用scan每次获取部分数据，再利用del删除每个field。（redis4.0以上支持lazy delete free模式）
    - 处理热点key：热点key可能会超过redis本身可以承受的QPS
      - 发现：monitor命令
      - 处理：
        - 拆分复杂数据结构
        - 迁移热点key
        - 本地缓存加发布订阅通知机制



其他
redis子进程：
int hasActiveChildProcess() {
    return server.rdb_child_pid != -1 ||
           server.aof_child_pid != -1 ||
           server.module_child_pid != -1;
}

布隆过滤器使用：
默认情况，下载安装redis时是不带布隆过滤器功能的，它是以插件的形式提供服务，需要手动加载（修改配置文件后重启redis或者用命令module load来动态加载）
下载和编译好布隆过滤器插件后，打开我们redis-server用的配置文件redis.conf，在MODULES模块下添加一行 loadmodule /usr/local/redis/redis-stable/RedisBloom-1.1.1/rebloom.so，之后重启redis即可
